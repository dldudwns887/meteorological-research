import xarray as xr
import numpy as np
import os
import pandas as pd
from scipy.spatial import cKDTree
from datetime import datetime, timedelta
from multiprocessing import Pool, cpu_count

# âœ… ì €ì¥ ê²½ë¡œ ì„¤ì •
obs_save_dir = "/home/papalio/test_research/RMSE_TEST_2/DATA/OBS_TA"
mkprism_save_dir = "/home/papalio/test_research/RMSE_TEST_2/DATA/MKPRISE_TA"

os.makedirs(obs_save_dir, exist_ok=True)
os.makedirs(mkprism_save_dir, exist_ok=True)

# âœ… ì›ë³¸ ë°ì´í„° ê²½ë¡œ
base_sgd_dir = "/home/papalio/test_research/python_edu/test_2024/test_2024/DATA/org/sgd"

# âœ… ê°€ìƒì˜ ì‹œë„ ì¤‘ì‹¬ ì¢Œí‘œ (17ê°œ ì‹œë„)
stations = {
    "ì„œìš¸": (37.5665, 126.9780),
    "ë¶€ì‚°": (35.1796, 129.0756),
    "ëŒ€êµ¬": (35.8714, 128.6014),
    "ì¸ì²œ": (37.4563, 126.7052),
    "ê´‘ì£¼": (35.1595, 126.8526),
    "ëŒ€ì „": (36.3504, 127.3845),
    "ìš¸ì‚°": (35.5384, 129.3114),
    "ì„¸ì¢…": (36.4802, 127.2890),
    "ê²½ê¸°": (37.4138, 127.5183),
    "ê°•ì›": (37.8228, 128.1555),
    "ì¶©ë¶": (36.6357, 127.4912),
    "ì¶©ë‚¨": (36.6588, 126.6728),
    "ì „ë¶": (35.7175, 127.1530),
    "ì „ë‚¨": (34.8679, 126.9910),
    "ê²½ë¶": (36.5760, 128.5056),
    "ê²½ë‚¨": (35.4606, 128.2132),
    "ì œì£¼": (33.4996, 126.5312)
}

# âœ… ë³€í™˜í•  ë‚ ì§œ ëª©ë¡ ìƒì„±
start_date = datetime(2020, 1, 1)
end_date = datetime(2021, 12, 31)

dates = []
current_date = start_date
while current_date <= end_date:
    dates.append(current_date)
    current_date += timedelta(days=1)

# âœ… íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ (OBS & MK-PRISM ë³€í™˜)
def process_sgd_file(current_date):
    year = current_date.strftime("%Y")
    month = current_date.strftime("%m")
    day = current_date.strftime("%d")
    filename = f"sfc_grid_ta_{year}{month}{day}0000.nc"
    file_path = os.path.join(base_sgd_dir, year, month, day, filename)

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(file_path):
        print(f"ğŸš¨ {file_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ê±´ë„ˆëœ€.")
        return

    print(f"âœ… ë³€í™˜ ì¤‘: {file_path}")

    # âœ… NetCDF íŒŒì¼ ë¡œë“œ
    ds = xr.open_dataset(file_path)
    data = ds["data"].values.astype(np.float32)
    data[data == -9990] = np.nan  # ê²°ì¸¡ê°’ ì²˜ë¦¬
    data /= ds["data"].attrs["data_scale"]  # ìŠ¤ì¼€ì¼ ì ìš©

    # âœ… ê²©ì í¬ê¸° ë° ìœ„ì¹˜ ì •ë³´
    grid_size = ds.attrs["grid_size"]
    grid_nx = int(ds.attrs["grid_nx"])
    grid_ny = int(ds.attrs["grid_ny"])
    map_slon = ds.attrs["map_slon"]
    map_slat = ds.attrs["map_slat"]

    lons = np.linspace(map_slon, map_slon + grid_size * (grid_nx - 1), grid_nx)
    lats = np.linspace(map_slat, map_slat + grid_size * (grid_ny - 1), grid_ny)
    lon_grid, lat_grid = np.meshgrid(lons, lats)

    # âœ… ìµœê·¼ì ‘ ê´€ì¸¡ì†Œ ë°ì´í„° ì¶”ì¶œ (OBS ë³€í™˜)
    tree = cKDTree(list(zip(lat_grid.ravel(), lon_grid.ravel())))
    station_coords = np.array(list(stations.values()))
    _, idxs = tree.query(station_coords)

    obs_temps = data.ravel()[idxs]

    obs_ds = xr.Dataset(
        {"temperature": (["station"], obs_temps)},
        coords={"station": list(stations.keys())}
    )
    obs_save_path = os.path.join(obs_save_dir, f"obs_ta_{year}{month}{day}0000.nc")
    obs_ds.to_netcdf(obs_save_path)
    print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {obs_save_path}")

    # âœ… MK-PRISM ë³´ì • (ê³ ë„ ë³´ì • ì ìš©)
    lapse_rate = -6.5  # ê¸°ì˜¨ê°ë¥  (Â°C/km)
    estimated_heights = np.random.uniform(400, 600, size=data.shape)  # ëœë¤ ê³ ë„ (400~600m)

    data_corrected = data + lapse_rate * (estimated_heights - 500) / 1000

    mkprism_ds = xr.Dataset(
        {"temperature": (["ny", "nx"], data_corrected)},
        coords={"ny": np.arange(data.shape[0]), "nx": np.arange(data.shape[1])}
    )
    mkprism_save_path = os.path.join(mkprism_save_dir, f"mkprism_ta_{year}{month}{day}0000.nc")
    mkprism_ds.to_netcdf(mkprism_save_path)
    print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {mkprism_save_path}")

# âœ… ë©€í‹°í”„ë¡œì„¸ì‹± ì‹¤í–‰
if __name__ == "__main__":
    num_workers = min(cpu_count(), 4)  # ìµœëŒ€ 8ê°œì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‚¬ìš©
    print(f"ğŸš€ ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ (ì‚¬ìš©í•  CPU ì½”ì–´ ìˆ˜: {num_workers})")

    with Pool(num_workers) as pool:
        pool.map(process_sgd_file, dates)

    print("ğŸ‰ ëª¨ë“  ë³€í™˜ ì™„ë£Œ!")
